{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rwL64qb8prA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e3a298-8def-4872-d0f5-97f4c153d3b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heZllQNm9vJd",
        "outputId": "775da62b-ee79-4321-9bfa-10345bc51ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDdVfdk28qse",
        "outputId": "0cf9d955-34ef-424f-ccfa-a4983c4dd80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Udem/Sem2/Representation_Learning/IFT6135_Programming\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Udem/Sem2/Representation_Learning/IFT6135_Programming/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGTJ6bHW0Uwi",
        "outputId": "f39d76b5-7524-4556-aeec-a744258cfcc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'GraphFlow' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hugochan/GraphFlow.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MattScicluna/IFT6135_Programming.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyEalBNZVe7H",
        "outputId": "2f9a3d46-766a-4bc4-bc0c-34948aa95ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IFT6135_Programming'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 130 (delta 56), reused 79 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (130/130), 3.64 MiB | 15.47 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfYqBK-m-cfH",
        "outputId": "61a43081-40d0-4dd7-f36e-cdbef1a5a19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr  3 17:31:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKAjqowQ93EY",
        "outputId": "f8c96352-ec1f-4c37-8f77-b94a31eef13f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Udem/Sem2/Representation_Learning/IFT6135_Programming/GraphFlow\n"
          ]
        }
      ],
      "source": [
        "%cd GraphFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGJ_zQa59Qgc",
        "outputId": "7a43068e-24fa-48bb-fc44-68cfb3ed4ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  GraphFlow.jpg  LICENSE  README.md  requirements.txt  src\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJW4tjHttlIc",
        "outputId": "18e03d04-2092-4f49-ee74-b3821415d1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 1.10.0+cu111\n",
            "Uninstalling torch-1.10.0+cu111:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.7/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch-1.10.0+cu111.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torch-1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDKOggA9ya0F",
        "outputId": "cd3d9f31-eaa7-4c3f-de2f-ff52a7067aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==0.4.1.post2\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torch-0.4.1.post2-cp37-cp37m-linux_x86_64.whl (512.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 512.7 MB 871 bytes/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 0.4.1.post2 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 0.4.1.post2 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 0.4.1.post2 which is incompatible.\n",
            "fastai 1.0.61 requires torch>=1.0.0, but you have torch 0.4.1.post2 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-0.4.1.post2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==0.4.1.post2 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "swpVnmyXthSC",
        "outputId": "0d228d35-119e-4c61-a5ec-f75241eb1f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim==3.5.0\n",
            "  Downloading gensim-3.5.0.tar.gz (22.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.9 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting numpy==1.14.5\n",
            "  Downloading numpy-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (12.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2 MB 57.4 MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 86.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.5.0->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.5.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: smart_open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.5.0->-r requirements.txt (line 1)) (5.2.1)\n",
            "Building wheels for collected packages: gensim, PyYAML\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-3.5.0-cp37-cp37m-linux_x86_64.whl size=24251604 sha256=9bc28280d11b294ad7b3b29dc351478bfd3b448eaa6e23779feaaebc976d57ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/7b/8f/f13d409ac83188758646a19c02797eb1dc2d8163e0d73a3f83\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=642cb5b5cbddb7171040231f22e9ff967d349258553add9e06ac1d5b468603da\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built gensim PyYAML\n",
            "Installing collected packages: numpy, PyYAML, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "yellowbrick 1.4 requires numpy>=1.16.0, but you have numpy 1.14.5 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.14.5 which is incompatible.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 0.4.1.post2 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 0.4.1.post2 which is incompatible.\n",
            "tifffile 2021.11.2 requires numpy>=1.15.1, but you have numpy 1.14.5 which is incompatible.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.14.5 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.14.5 which is incompatible.\n",
            "spacy 2.2.4 requires numpy>=1.15.0, but you have numpy 1.14.5 which is incompatible.\n",
            "seaborn 0.11.2 requires numpy>=1.15, but you have numpy 1.14.5 which is incompatible.\n",
            "scikit-learn 1.0.2 requires numpy>=1.14.6, but you have numpy 1.14.5 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.14.5 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.14.5 which is incompatible.\n",
            "pymc3 3.11.4 requires numpy>=1.15.0, but you have numpy 1.14.5 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.14.5 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.14.5 which is incompatible.\n",
            "plotnine 0.6.0 requires numpy>=1.16.0, but you have numpy 1.14.5 which is incompatible.\n",
            "pandas 1.3.5 requires numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.14.5 which is incompatible.\n",
            "numba 0.51.2 requires numpy>=1.15, but you have numpy 1.14.5 which is incompatible.\n",
            "librosa 0.8.1 requires numpy>=1.15.0, but you have numpy 1.14.5 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.14.5 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.14.5 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.14.5 which is incompatible.\n",
            "imgaug 0.2.9 requires numpy>=1.15.0, but you have numpy 1.14.5 which is incompatible.\n",
            "fbprophet 0.7.1 requires numpy>=1.15.4, but you have numpy 1.14.5 which is incompatible.\n",
            "fastai 1.0.61 requires numpy>=1.15, but you have numpy 1.14.5 which is incompatible.\n",
            "fastai 1.0.61 requires torch>=1.0.0, but you have torch 0.4.1.post2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cvxpy 1.0.31 requires numpy>=1.15, but you have numpy 1.14.5 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.14.5 which is incompatible.\n",
            "blis 0.4.1 requires numpy>=1.15.0, but you have numpy 1.14.5 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.14.5 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-5.1 gensim-3.5.0 numpy-1.14.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a5IYMfYFSJP",
        "outputId": "3d8fb05f-71d6-44ce-bf7e-c0a9fa33b012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycorenlp\n",
            "  Downloading pycorenlp-0.3.0.tar.gz (1.3 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pycorenlp) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pycorenlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pycorenlp) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pycorenlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pycorenlp) (3.0.4)\n",
            "Building wheels for collected packages: pycorenlp\n",
            "  Building wheel for pycorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycorenlp: filename=pycorenlp-0.3.0-py3-none-any.whl size=2145 sha256=defe9ed4731efaeff9ea3fb3ee1936eaaa3ef838d510353504bc369762a1ca1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/d8/ad/6b2276343ac605ee47e6beddb28331e96377909e5c816539c3\n",
            "Successfully built pycorenlp\n",
            "Installing collected packages: pycorenlp\n",
            "Successfully installed pycorenlp-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pycorenlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roG8I7qCpdoz",
        "outputId": "9241f2fa-73f4-493b-abb4-a341f0725f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 123 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (0.4.1.post2)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.32-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 28.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.63.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.7 MB/s \n",
            "\u001b[?25hCollecting botocore<1.25.0,>=1.24.32\n",
            "  Downloading botocore-1.24.32-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 78.3 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.32->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 77.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.32->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 82.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "librosa 0.8.1 requires numpy>=1.15.0, but you have numpy 1.14.5 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.14.5 which is incompatible.\n",
            "fastai 1.0.61 requires numpy>=1.15, but you have numpy 1.14.5 which is incompatible.\n",
            "fastai 1.0.61 requires torch>=1.0.0, but you have torch 0.4.1.post2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.32 botocore-1.24.32 jmespath-1.0.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.2 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-pretrained-bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VSYSCilA9z2",
        "outputId": "05d061ca-c121-4ff7-acc0-db2ce9aab1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************** MODEL CONFIGURATION ****************\n",
            "answer_marker_embed_dim  -->   10\n",
            "batch_size               -->   1\n",
            "bert_dim                 -->   1024\n",
            "bert_doc_stride          -->   250\n",
            "bert_dropout             -->   0.4\n",
            "bert_layer_indexes       -->   [0, 24]\n",
            "bert_max_seq_len         -->   500\n",
            "bert_model               -->   bert-large-uncased\n",
            "bignn                    -->   True\n",
            "ctx_exact_match_embed_dim -->   3\n",
            "ctx_graph_hops           -->   5\n",
            "ctx_graph_topk           -->   10\n",
            "ctx_ner_embed_dim        -->   8\n",
            "ctx_pos_embed_dim        -->   12\n",
            "cuda_id                  -->   0\n",
            "dataset_name             -->   coqa\n",
            "devset                   -->   data/coqa/dev.json\n",
            "embed_file               -->   data/coqa/glove.840B.300d.txt\n",
            "embed_type               -->   glove\n",
            "f_ner                    -->   True\n",
            "f_pos                    -->   True\n",
            "f_qem                    -->   True\n",
            "f_tf                     -->   False\n",
            "finetune_bert            -->   False\n",
            "fix_vocab_embed          -->   True\n",
            "grad_accumulated_steps   -->   1\n",
            "grad_clipping            -->   10\n",
            "graph_learner_num_pers   -->   1\n",
            "hidden_size              -->   300\n",
            "learning_rate            -->   0.0005\n",
            "logging                  -->   True\n",
            "max_answer_len           -->   12\n",
            "max_epochs               -->   30\n",
            "max_position_distance    -->   160\n",
            "max_turn_num             -->   50\n",
            "min_freq                 -->   5\n",
            "n_history                -->   2\n",
            "n_spatial_kernels        -->   2\n",
            "no_cuda                  -->   False\n",
            "no_pre_answer            -->   False\n",
            "no_pre_question          -->   False\n",
            "optimizer                -->   adamax\n",
            "out_dir                  -->   ../out/coqa/graphflow_dynamic_graph\n",
            "out_pred_in_folder       -->   True\n",
            "out_predictions          -->   True\n",
            "patience                 -->   10\n",
            "position_emb_size        -->   50\n",
            "predict_raw_text         -->   True\n",
            "predict_train            -->   True\n",
            "pretrained               -->   None\n",
            "ques_marker_embed_dim    -->   3\n",
            "ques_turn_marker_embed_dim -->   5\n",
            "random_seed              -->   1234\n",
            "rnn_dropout              -->   0.3\n",
            "rnn_input_dropout        -->   None\n",
            "save_params              -->   True\n",
            "saved_vocab_file         -->   data/coqa/word_model_min_5\n",
            "shuffle                  -->   True\n",
            "static_graph             -->   False\n",
            "temporal_gnn             -->   True\n",
            "test_batch_size          -->   1\n",
            "testset                  -->   None\n",
            "top_vocab                -->   200000\n",
            "trainset                 -->   data/coqa/train.json\n",
            "use_bert                 -->   True\n",
            "use_bert_gamma           -->   False\n",
            "use_bert_weight          -->   True\n",
            "use_gnn                  -->   True\n",
            "use_position_enc         -->   False\n",
            "use_ques_marker          -->   True\n",
            "use_spatial_kernels      -->   False\n",
            "verbose                  -->   1000\n",
            "vocab_embed_size         -->   300\n",
            "word_dropout             -->   0.3\n",
            "**************** MODEL CONFIGURATION ****************\n",
            "[ Using CUDA ]\n",
            "<> <> <> Starting Timer [Load data/coqa/train.json] <> <> <>\n",
            "Load 7199 paragraphs.\n",
            "Turn num: avg = 15.1, min = 1, max = 36\n",
            "Paragraph length: avg = 320.5, min = 87, max = 1207\n",
            "Question length: avg = 23.3, min = 1, max = 437\n",
            "<> <> <> Finished Timer [Load data/coqa/train.json] <> <> <> Total time elapsed: 0h 00m 25s <> <> <>\n",
            "<> <> <> Starting Timer [Load data/coqa/dev.json] <> <> <>\n",
            "Load 500 paragraphs.\n",
            "Turn num: avg = 16.0, min = 10, max = 25\n",
            "Paragraph length: avg = 309.3, min = 142, max = 1002\n",
            "Question length: avg = 23.1, min = 3, max = 68\n",
            "<> <> <> Finished Timer [Load data/coqa/dev.json] <> <> <> Total time elapsed: 0h 00m 01s <> <> <>\n",
            "[ Using pretrained BERT features ]\n",
            "100% 231508/231508 [00:00<00:00, 320617.34B/s]\n",
            "100% 1248501532/1248501532 [01:46<00:00, 11730856.73B/s]\n",
            "[ Fix BERT layers ]\n",
            "Train vocab: 70921\n",
            "Pruned train vocab: 67233\n",
            "Loading pre-built vocabs stored in data/coqa/word_model_min_5\n",
            "46 pos tags: {':', 'POS', \"''\", 'PRP', 'RBR', 'JJ', 'NN', 'RB', 'NNS', 'unk_pos', 'WDT', 'DT', 'IN', 'WP$', '``', 'MD', '-LRB-', 'WRB', 'WP', 'JJR', 'FW', 'RP', 'LS', 'SYM', 'PDT', 'RBS', 'VBD', 'NNP', 'JJS', 'TO', '#', 'CC', '$', 'VB', 'PRP$', 'NNPS', 'VBG', ',', '.', 'VBN', 'EX', '-RRB-', 'VBP', 'VBZ', 'UH', 'CD'}\n",
            "25 ner tags: {'SET', 'ORGANIZATION', 'CITY', 'ORDINAL', 'URL', 'STATE_OR_PROVINCE', 'MISC', 'PERSON', 'MONEY', 'PERCENT', 'CRIMINAL_CHARGE', 'LOCATION', 'RELIGION', 'DATE', 'unk_ner', 'IDEOLOGY', 'COUNTRY', 'NUMBER', 'NATIONALITY', 'O', 'TITLE', 'CAUSE_OF_DEATH', 'DURATION', 'HANDLE', 'TIME'}\n",
            "[ Fix word embeddings ]\n",
            "[ Using bidirectional lstm encoder ]\n",
            "[ Using bidirectional lstm encoder ]\n",
            "[ Using bidirectional lstm encoder ]\n",
            "[ Using lstm encoder ]\n",
            "[ Multi-perspective GraphLearner: 1 ]\n",
            "[ Using 5-hop ContextGraphNN ]\n",
            "[ Using graph type: dynamic ]\n",
            "[ Using 5-hop ContextGraphNN ]\n",
            "[ Using graph type: dynamic ]\n",
            "logits_bert_layers: torch.Size([1, 24])\n",
            "word_embed.weight: torch.Size([67237, 300])\n",
            "ctx_exact_match_embed.weight: torch.Size([2, 3])\n",
            "ctx_pos_embed.weight: torch.Size([46, 12])\n",
            "ctx_ner_embed.weight: torch.Size([25, 8])\n",
            "ctx_ans_marker_embed.weight: torch.Size([9, 10])\n",
            "ques_marker_embed.weight: torch.Size([5, 3])\n",
            "ques_enc.model.weight_ih_l0: torch.Size([600, 1327])\n",
            "ques_enc.model.weight_hh_l0: torch.Size([600, 150])\n",
            "ques_enc.model.bias_ih_l0: torch.Size([600])\n",
            "ques_enc.model.bias_hh_l0: torch.Size([600])\n",
            "ques_enc.model.weight_ih_l0_reverse: torch.Size([600, 1327])\n",
            "ques_enc.model.weight_hh_l0_reverse: torch.Size([600, 150])\n",
            "ques_enc.model.bias_ih_l0_reverse: torch.Size([600])\n",
            "ques_enc.model.bias_hh_l0_reverse: torch.Size([600])\n",
            "ctx_enc_l1.model.weight_ih_l0: torch.Size([600, 1667])\n",
            "ctx_enc_l1.model.weight_hh_l0: torch.Size([600, 150])\n",
            "ctx_enc_l1.model.bias_ih_l0: torch.Size([600])\n",
            "ctx_enc_l1.model.bias_hh_l0: torch.Size([600])\n",
            "ctx_enc_l1.model.weight_ih_l0_reverse: torch.Size([600, 1667])\n",
            "ctx_enc_l1.model.weight_hh_l0_reverse: torch.Size([600, 150])\n",
            "ctx_enc_l1.model.bias_ih_l0_reverse: torch.Size([600])\n",
            "ctx_enc_l1.model.bias_hh_l0_reverse: torch.Size([600])\n",
            "ctx_enc_l2.model.weight_ih_l0: torch.Size([600, 600])\n",
            "ctx_enc_l2.model.weight_hh_l0: torch.Size([600, 150])\n",
            "ctx_enc_l2.model.bias_ih_l0: torch.Size([600])\n",
            "ctx_enc_l2.model.bias_hh_l0: torch.Size([600])\n",
            "ctx_enc_l2.model.weight_ih_l0_reverse: torch.Size([600, 600])\n",
            "ctx_enc_l2.model.weight_hh_l0_reverse: torch.Size([600, 150])\n",
            "ctx_enc_l2.model.bias_ih_l0_reverse: torch.Size([600])\n",
            "ctx_enc_l2.model.bias_hh_l0_reverse: torch.Size([600])\n",
            "rnn_ques_over_time.model.weight_ih_l0: torch.Size([1200, 300])\n",
            "rnn_ques_over_time.model.weight_hh_l0: torch.Size([1200, 300])\n",
            "rnn_ques_over_time.model.bias_ih_l0: torch.Size([1200])\n",
            "rnn_ques_over_time.model.bias_hh_l0: torch.Size([1200])\n",
            "ctx2ques_attn.linear_sim.weight: torch.Size([300, 300])\n",
            "ctx2ques_attn_l2.linear_sim.weight: torch.Size([300, 1624])\n",
            "ques_self_atten.W1: torch.Size([300, 300])\n",
            "ques_self_atten.W2: torch.Size([300, 1])\n",
            "graph_learner.weight_tensor: torch.Size([1, 1667])\n",
            "ctx_gnn.gru_step.linear_z.weight: torch.Size([300, 600])\n",
            "ctx_gnn.gru_step.linear_r.weight: torch.Size([300, 600])\n",
            "ctx_gnn.gru_step.linear_t.weight: torch.Size([300, 600])\n",
            "ctx_gnn.gated_fusion.fc_z.weight: torch.Size([300, 1200])\n",
            "ctx_gnn.gated_fusion.fc_z.bias: torch.Size([300])\n",
            "ctx_gnn_l2.gru_step.linear_z.weight: torch.Size([300, 600])\n",
            "ctx_gnn_l2.gru_step.linear_r.weight: torch.Size([300, 600])\n",
            "ctx_gnn_l2.gru_step.linear_t.weight: torch.Size([300, 600])\n",
            "ctx_gnn_l2.gated_fusion.fc_z.weight: torch.Size([300, 1200])\n",
            "ctx_gnn_l2.gated_fusion.fc_z.bias: torch.Size([300])\n",
            "graph_gru_step.fc_z.weight: torch.Size([300, 1200])\n",
            "graph_gru_step.fc_z.bias: torch.Size([300])\n",
            "graph_gru_step_l2.fc_z.weight: torch.Size([300, 1200])\n",
            "graph_gru_step_l2.fc_z.bias: torch.Size([300])\n",
            "gru_step.linear_z.weight: torch.Size([300, 600])\n",
            "gru_step.linear_r.weight: torch.Size([300, 600])\n",
            "gru_step.linear_t.weight: torch.Size([300, 600])\n",
            "linear_start.weight: torch.Size([300, 300])\n",
            "linear_end.weight: torch.Size([300, 300])\n",
            "fc_clf.weight: torch.Size([2400, 300])\n",
            "fc_clf.bias: torch.Size([2400])\n",
            "#Parameters = 30387154\n",
            "\n",
            "<> <> <> Starting Timer [Train] <> <> <>\n",
            "\n",
            ">>> Train Epoch: [1 / 30]\n",
            "[train-1] step: [1000 / 7199] | loss = 9.7425 | F1 = 12.70 | EM = 8.08\n",
            "used_time: 821.62s\n",
            "[train-1] step: [2000 / 7199] | loss = 8.6527 | F1 = 22.02 | EM = 15.12\n",
            "used_time: 1636.40s\n",
            "[train-1] step: [3000 / 7199] | loss = 7.9500 | F1 = 28.04 | EM = 19.73\n",
            "used_time: 2464.83s\n",
            "[train-1] step: [4000 / 7199] | loss = 7.4506 | F1 = 31.98 | EM = 22.78\n",
            "used_time: 3271.65s\n",
            "[train-1] step: [5000 / 7199] | loss = 7.0952 | F1 = 34.89 | EM = 25.02\n",
            "used_time: 4094.95s\n",
            "[train-1] step: [6000 / 7199] | loss = 6.7950 | F1 = 37.33 | EM = 27.05\n",
            "used_time: 4895.10s\n",
            "[train-1] step: [7000 / 7199] | loss = 6.5789 | F1 = 39.18 | EM = 28.58\n",
            "used_time: 5697.34s\n",
            "<> <> Timer [Train] <> <> Interval [Training Epoch 1]: 1h 37m 37s <> <>\n",
            "Training Epoch 1 -- Loss: 6.5423 | F1 = 39.49 | EM = 28.85\n",
            "\n",
            ">>> Dev Epoch: [1 / 30]\n",
            "<> <> Timer [Train] <> <> Interval [Validation Epoch 1]: 0h 03m 18s <> <>\n",
            "Validation Epoch 1 -- Loss: 4.5295 | F1 = 64.27 | EM = 53.73\n",
            "Saved model to ../out/coqa/graphflow_dynamic_graph\n",
            "!!! Updated: \n",
            "F1 = 64.27\n",
            "EM = 53.73\n",
            "\n",
            "\n",
            ">>> Train Epoch: [2 / 30]\n",
            "[train-2] step: [1000 / 7199] | loss = 4.9198 | F1 = 52.95 | EM = 40.09\n",
            "used_time: 831.93s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python src/main.py -config src/config/graphflow_dynamic_graph_coqa.yml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wdmXeVuGC9sH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GraphFlow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}