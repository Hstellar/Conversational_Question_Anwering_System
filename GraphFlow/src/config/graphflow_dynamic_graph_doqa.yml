# Data
dataset_name: 'doqa'
trainset: '../data/doqa/train.json'
devset: '../data/doqa/dev.json'
testset: '../data/doqa/test.json'
embed_file: '/home/cheny39/glove-vectors/glove.840B.300d.txt'
saved_vocab_file: '../data/doqa/word_model_min_5'
pretrained: null


# Output
out_dir: '../out/doqa/graphflow_dynamic_graph'


# Preprocessing
min_freq: 5
top_vocab: 200000
n_history: 2 # 2!
no_pre_question: False
no_pre_answer: False
max_turn_num: 8



# Model
embed_type: 'glove'
vocab_embed_size: 300
fix_vocab_embed: True # True!
f_qem: True # Context exact match feature
f_pos: True # Context POS feature
f_ner: True # Context NER feature
f_tf: False # Context TF feature
ctx_exact_match_embed_dim: 3
ctx_pos_embed_dim: 12
ctx_ner_embed_dim: 8
answer_marker_embed_dim: 10 # 10!
use_ques_marker: True
ques_marker_embed_dim: 3 # 3!
ques_turn_marker_embed_dim: 5 # 5!

hidden_size: 128 # 128!
word_dropout: 0.4 # 0.4!
bert_dropout: 0.2 # 0.2!
rnn_dropout: 0.4 # 0.4!
rnn_input_dropout: null

# Graph neural networks
use_gnn: True
bignn: False
static_graph: False
temporal_gnn: True
ctx_graph_hops: 5 # 5!
ctx_graph_topk: 10 # 10!
graph_learner_num_pers: 1 # 1
stacked_layer: False # False


# Spatial kernels
use_spatial_kernels: False
n_spatial_kernels: 2
use_position_enc: False
max_position_distance: 160
position_emb_size: 50


# Bert configure
use_bert: True # True
finetune_bert: False # False
use_bert_weight: True
use_bert_gamma: False
bert_model: 'bert-large-uncased'
bert_dim: 1024
bert_max_seq_len: 500
bert_doc_stride: 250 #
bert_layer_indexes:
  - 0
  - 24


# Optimizer
optimizer: 'adamax'
learning_rate: 0.0005 # 0.0005!
grad_clipping: 5 # 5!


# Training & testing
random_seed: 1234
shuffle: True # Whether to shuffle the examples during training
batch_size: 1 # No. of dialogs per batch, 1!
grad_accumulated_steps: 1
max_epochs: 30
patience: 10
verbose: 1000 # Print every X batches
unk_answer_threshold: 0.2 # 0.2!
max_answer_len: 30 # Set max answer length for decoding # 30! 35!
predict_train: True # Whether to predict on training set
out_predictions: True # Whether to output predictions
predict_raw_text: True # Whether to use raw text and offsets for prediction
save_params: True # Whether to save params
logging: True # Turn it off for Codalab
out_pred_in_folder: True # Turn it off for Codalab


# Device
no_cuda: False
cuda_id: -1
